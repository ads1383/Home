{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-FpwxQZFZXZ"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "HVMsN192DZ-F",
    "outputId": "809bf406-ca6c-4ab1-9d4b-f5d7504e1aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzHVPDHvYYYr"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaXmOjgsFZXf"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    \"\"\"\n",
    "    The Tic-Tac-Toe Environment\n",
    "    \"\"\"\n",
    "    # possible ways to win\n",
    "    win_set = frozenset([(0,1,2), (3,4,5), (6,7,8), # horizontal\n",
    "                         (0,3,6), (1,4,7), (2,5,8), # vertical\n",
    "                         (0,4,8), (2,4,6)])         # diagonal\n",
    "    # statuses\n",
    "    STATUS_VALID_MOVE = 'valid'\n",
    "    STATUS_INVALID_MOVE = 'inv'\n",
    "    STATUS_WIN = 'win'\n",
    "    STATUS_TIE = 'tie'\n",
    "    STATUS_LOSE = 'lose'\n",
    "    STATUS_DONE = 'done'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the game to an empty board.\"\"\"\n",
    "        self.grid = np.array([0] * 9) # grid\n",
    "        self.turn = 1                 # whose turn it is\n",
    "        self.done = False             # whether game is done\n",
    "        return self.grid\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Print what is on the board.\"\"\"\n",
    "        map = {0:'.', 1:'x', 2:'o'} # grid label vs how to plot\n",
    "        print(''.join(map[i] for i in self.grid[0:3]))\n",
    "        print(''.join(map[i] for i in self.grid[3:6]))\n",
    "        print(''.join(map[i] for i in self.grid[6:9]))\n",
    "        print('====')\n",
    "\n",
    "    def check_win(self):\n",
    "        \"\"\"Check if someone has won the game.\"\"\"\n",
    "        for pos in self.win_set:\n",
    "            s = set([self.grid[p] for p in pos])\n",
    "            if len(s) == 1 and (0 not in s):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Mark a point on position action.\"\"\"\n",
    "        action = int(action)\n",
    "        assert type(action) == int and action >= 0 and action < 9\n",
    "        # done = already finished the game\n",
    "        if self.done:\n",
    "            return self.grid, self.STATUS_DONE, self.done\n",
    "        # action already have something on it\n",
    "        if self.grid[action] != 0:\n",
    "            return self.grid, self.STATUS_INVALID_MOVE, self.done\n",
    "        # play move\n",
    "        self.grid[action] = self.turn\n",
    "        if self.turn == 1:\n",
    "            self.turn = 2\n",
    "        else:\n",
    "            self.turn = 1\n",
    "        # check win\n",
    "        if self.check_win():\n",
    "            self.done = True\n",
    "            return self.grid, self.STATUS_WIN, self.done\n",
    "        # check tie\n",
    "        if all([p != 0 for p in self.grid]):\n",
    "            self.done = True\n",
    "            return self.grid, self.STATUS_TIE, self.done\n",
    "        return self.grid, self.STATUS_VALID_MOVE, self.done\n",
    "\n",
    "    def random_step(self):\n",
    "        \"\"\"Choose a random, unoccupied move on the board to play.\"\"\"\n",
    "        pos = [i for i in range(9) if self.grid[i] == 0]\n",
    "        move = random.choice(pos)\n",
    "        return self.step(move)\n",
    "\n",
    "    def play_against_random(self, action):\n",
    "        \"\"\"Play a move, and then have a random agent play the next move.\"\"\"\n",
    "        state, status, done = self.step(action)\n",
    "        if not done and self.turn == 2:\n",
    "            state, s2, done = self.random_step()\n",
    "            if done:\n",
    "                if s2 == self.STATUS_WIN:\n",
    "                    status = self.STATUS_LOSE\n",
    "                elif s2 == self.STATUS_TIE:\n",
    "                    status = self.STATUS_TIE\n",
    "                else:\n",
    "                    raise ValueError(\"???\")\n",
    "        return state, status, done\n",
    "     \n",
    "    def play_qustom_player(self, action, player):\n",
    "        \"\"\"Play a move, and then have a random agent play the next move.\"\"\"\n",
    "        state, status, done = self.step(action)\n",
    "        if not done and self.turn == 2:\n",
    "            act, _ = select_action(player, state)\n",
    "            state, s2, done = self.step(act)\n",
    "            if done:\n",
    "                if s2 == self.STATUS_WIN:\n",
    "                    status = self.STATUS_LOSE\n",
    "                elif s2 == self.STATUS_TIE:\n",
    "                    status = self.STATUS_TIE\n",
    "                else:\n",
    "                    raise ValueError(\"???\")\n",
    "        return state, status, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90tqswUxFZX1"
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    \"\"\"\n",
    "    The Tic-Tac-Toe Policy\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=27, hidden_size=64, output_size=9):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = F.softmax(self.fc2(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kj57WsAkFZX5"
   },
   "outputs": [],
   "source": [
    "def select_action(policy, state):\n",
    "    \"\"\"Samples an action from the policy at the state.\"\"\"\n",
    "    state = torch.from_numpy(state).long().unsqueeze(0)\n",
    "    state = torch.zeros(3,9).scatter_(0,state,1).view(1,27)\n",
    "    #pr = policy(state)\n",
    "    pr = policy(Variable(state))\n",
    "    m = torch.distributions.Categorical(pr) \n",
    "    action = m.sample()\n",
    "    log_prob = torch.sum(m.log_prob(action))\n",
    "    \n",
    "    return action.data[0], log_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihTfoz6qFZX9"
   },
   "outputs": [],
   "source": [
    "def compute_returns(rewards, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute returns for each time step, given the rewards\n",
    "      @param rewards: list of floats, where rewards[t] is the reward\n",
    "                      obtained at time step t\n",
    "      @param gamma: the discount factor\n",
    "      @returns list of floats representing the episode's returns\n",
    "          G_t = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... \n",
    "\n",
    "    >>> compute_returns([0,0,0,1], 1.0)\n",
    "    [1.0, 1.0, 1.0, 1.0]\n",
    "    >>> compute_returns([0,0,0,1], 0.9)\n",
    "    [0.7290000000000001, 0.81, 0.9, 1.0]\n",
    "    >>> compute_returns([0,-0.5,5,0.5,-10], 0.9)\n",
    "    [-2.5965000000000003, -2.8850000000000002, -2.6500000000000004, -8.5, -10.0]\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    x = 0\n",
    "    for i in range(len(rewards)):\n",
    "        x = rewards[i]\n",
    "        for j in range(0,len(rewards)-i):\n",
    "            if j!=0:\n",
    "                x= x + rewards[i + j]*gamma**j\n",
    "    \n",
    "        r.append(x)\n",
    "    return r    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WR-tZt0HFZYF"
   },
   "outputs": [],
   "source": [
    "def finish_episode(saved_rewards, saved_logprobs, gamma=1.0):\n",
    "    \"\"\"Samples an action from the policy at the state.\"\"\"\n",
    "    policy_loss = []\n",
    "    returns = compute_returns(saved_rewards, gamma)\n",
    "    returns = torch.Tensor(returns)\n",
    "  \n",
    "    # subtract mean and std for faster training\n",
    "    returns = (returns - returns.mean()) / (returns.std() +\n",
    "                                            np.finfo(np.float32).eps)\n",
    "   \n",
    "    for log_prob, reward in zip(saved_logprobs, returns):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "       \n",
    "    policy_loss = torch.stack(policy_loss).sum()\n",
    "   \n",
    "    policy_loss.backward(retain_graph=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERDaUYbBFZYJ"
   },
   "outputs": [],
   "source": [
    "def get_reward(status):\n",
    "    \"\"\"Returns a numeric given an environment status.\"\"\"\n",
    "    return {\n",
    "            Environment.STATUS_VALID_MOVE  : 0, \n",
    "            Environment.STATUS_INVALID_MOVE: -5,\n",
    "            Environment.STATUS_WIN         : 1,\n",
    "            Environment.STATUS_TIE         : 0.5,\n",
    "            Environment.STATUS_LOSE        : -1\n",
    "    }[status]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWu14wq_FZYN"
   },
   "outputs": [],
   "source": [
    "def train(policy, env, gamma=0.98, log_interval=10000):\n",
    "    \"\"\"Train policy gradient.\"\"\"\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=10000, gamma=0.9)\n",
    "    running_reward = 0\n",
    "\n",
    "    for i_episode in count(1):\n",
    "        saved_rewards = []\n",
    "        saved_logprobs = []\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        optimizer.zero_grad()\n",
    "        while not done:\n",
    "            action, logprob = select_action(policy, state)\n",
    "            \n",
    "            state, status, done = env.play_against_random(action)\n",
    "       \n",
    "            reward = get_reward(status)\n",
    "            #if reward == -5:\n",
    "             # done = True\n",
    "           \n",
    "            saved_logprobs.append(logprob)\n",
    "            saved_rewards.append(reward)\n",
    "           \n",
    " \n",
    "        R = compute_returns(saved_rewards)[0]\n",
    "        running_reward += R\n",
    "\n",
    "        finish_episode(saved_rewards, saved_logprobs, gamma)\n",
    "        \n",
    "        \n",
    "        if i_episode % log_interval == 0:\n",
    "            print('Episode {}\\tAverage return: {:.2f}'.format(\n",
    "                i_episode,\n",
    "                running_reward / log_interval))\n",
    "            running_reward = 0\n",
    "\n",
    "        if i_episode % (log_interval) == 0:\n",
    "            torch.save(policy.state_dict(),\n",
    "                       \"./RL/policy-%d.pkl\" % i_episode)\n",
    "\n",
    "        if i_episode % 16 == 0: # batch_size\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IIOMRwcVFZYR"
   },
   "outputs": [],
   "source": [
    "def first_move_distr(policy, env):\n",
    "    \"\"\"Display the distribution of first moves.\"\"\"\n",
    "    state = env.reset()\n",
    "    state = torch.from_numpy(state).long().unsqueeze(0)\n",
    "    state = torch.zeros(3,9).scatter_(0,state,1).view(1,27)\n",
    "    pr = policy(Variable(state))\n",
    "    return pr.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ITK9sDOFZYV"
   },
   "outputs": [],
   "source": [
    "def load_weights(policy, episode):\n",
    "    \"\"\"Load saved weights\"\"\"\n",
    "    weights = torch.load(\"./RL/policy-%d.pkl\" % episode)\n",
    "    policy.load_state_dict(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNwpaIb_FZYZ"
   },
   "outputs": [],
   "source": [
    "policy = Policy()\n",
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "wW9e1GHsGqZ0",
    "outputId": "a8e5320c-fcf0-4e72-99d5-927b4bb6d80b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000\tAverage return: -23.85\n",
      "Episode 20000\tAverage return: -15.83\n",
      "Episode 30000\tAverage return: -5.84\n",
      "Episode 40000\tAverage return: -1.65\n",
      "Episode 50000\tAverage return: -0.59\n",
      "Episode 60000\tAverage return: -0.39\n",
      "Episode 70000\tAverage return: -0.18\n",
      "Episode 80000\tAverage return: 0.22\n",
      "Episode 90000\tAverage return: 0.32\n",
      "Episode 100000\tAverage return: 0.41\n",
      "Episode 110000\tAverage return: 0.66\n",
      "Episode 120000\tAverage return: 0.51\n",
      "Episode 130000\tAverage return: 0.64\n",
      "Episode 140000\tAverage return: 0.61\n",
      "Episode 150000\tAverage return: 0.75\n",
      "Episode 160000\tAverage return: 0.58\n",
      "Episode 170000\tAverage return: 0.63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-748eebb19aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a060c29f571a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, env, gamma, log_interval)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mrunning_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mfinish_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-09f33e7d9fa3>\u001b[0m in \u001b[0;36mfinish_episode\u001b[0;34m(saved_rewards, saved_logprobs, gamma)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Samples an action from the policy at the state.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9f3eca909a3d>\u001b[0m in \u001b[0;36mcompute_returns\u001b[0;34m(rewards, gamma)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "mV0BPYgIGszX",
    "outputId": "fffad7e5-3698-4520-b6c7-84cd20652b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4975e-09, 1.0639e-11, 9.9994e-01, 2.4727e-12, 2.9912e-11, 6.9818e-12,\n",
      "         1.6910e-12, 7.2865e-12, 5.8808e-05]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "load_weights(policy, 800000)\n",
    "print(first_move_distr(policy, env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H530inQqN6xB"
   },
   "outputs": [],
   "source": [
    "def hod_setki(policy, grid):\n",
    "  action,_ = select_action(policy, grid)\n",
    "  #state = torch.from_numpy(grid).long().unsqueeze(0)\n",
    "  #state = torch.zeros(3,9).scatter_(0,state,1).view(1,27)\n",
    "  #pr = policy(Variable(state))\n",
    "  \n",
    "  #pr2 = pr.data.max(1, keepdim=True)[1]\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mzLnRqDDF7BU",
    "outputId": "52b16184-6505-4a58-a13f-df6e804c5beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "...\n",
      "...\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "PKLdmCwnGDBi",
    "outputId": "edc65fad-75f3-456b-a5f0-5503fdc1db31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 0, 0, 0, 0]), 'valid', False)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mmtb6KLeGLZc",
    "outputId": "2f9e1c62-f2f6-45ee-9a78-1c59fe8dd232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      "...\n",
      "...\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_-xFiN0CGPRT",
    "outputId": "2798f766-5ceb-4d2d-f7d6-dd1980eece44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 2, 0, 0, 0, 0]), 'valid', False)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UCOOhg8EGhLr",
    "outputId": "78d82f47-1383-4ee4-fe88-8946d5f4e5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".o.\n",
      "...\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "F7xKyNkEGlLu",
    "outputId": "b9f7d5e9-f617-4ba3-b94f-3c5816f92ad5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 2, 0, 0, 0, 1]), 'valid', False)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VK_El5xgG4Bs",
    "outputId": "1c56f9b3-b5ae-4d68-e071-e05cef0f1dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".o.\n",
      "..x\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LYhyRtvvJnP5",
    "outputId": "43e60ee3-20fd-4a6d-d493-1fbc96f5aeca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 2, 2, 0, 0, 1]), 'valid', False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8MvkehJXJsTH",
    "outputId": "87784154-84b3-4a19-b55d-64193a660165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".oo\n",
      "..x\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "2YnQ1mL_Jyau",
    "outputId": "9c1656df-e25f-4a30-9101-ae762438874d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 2, 2, 0, 0, 1]), 'valid', False)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_nR_kpvHKBov",
    "outputId": "0004fa7f-3249-4a1d-9f6f-64b94656f2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.x\n",
      ".oo\n",
      "..x\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1DUywAeMKIQL",
    "outputId": "ede26c05-984f-474e-ffc0-f225ac3c32e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 2, 0, 2, 1, 1, 2, 1]), 'valid', False)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "hokOY5iiXiPU",
    "outputId": "65c84d61-29d7-4c34-e5bc-2223d1eb6519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..o\n",
      ".ox\n",
      "xox\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Z-tg_m6dXmwg",
    "outputId": "c7abf2fa-fc13-42bb-9450-64185fe9eb02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 0, 2, 1, 1, 2, 1]), 'valid', False)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy,env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "IXJQ4765XqKy",
    "outputId": "39d09b21-e594-4376-9171-585568e52f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".xo\n",
      ".ox\n",
      "xox\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9dvyeiGEKLzw",
    "outputId": "f4a52179-cca8-4cc5-e8fe-003da1bc7cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OfishkXpPV6T",
    "outputId": "5383e4bf-7540-4337-b8fe-e655fa45ae26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 0, 0, 0, 0]), 'valid', False)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Cm18h5YVPZ8q",
    "outputId": "0a0b27b6-f9da-4b8e-e8f7-1c86c3ed5cdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 0, 0, 0, 2]), 'valid', False)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "lypiauWqPcQO",
    "outputId": "b6158fb4-db8a-49c3-a3af-700ffd6d1b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      "...\n",
      "..o\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "piA25sIcPfq3",
    "outputId": "be6d8bc1-2638-4929-bd50-dc2606652037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 1, 0, 0, 0, 2]), 'valid', False)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VQIwCInMPsra",
    "outputId": "8cf89d9f-1ab9-4c27-b174-e3e282cb9dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".x.\n",
      "..o\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "c0omLaUTPuqo",
    "outputId": "938aebb1-afc7-48ab-a428-78fe1e752436"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 1, 0, 2, 0, 2]), 'valid', False)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2VjoVzXlPyN-",
    "outputId": "5107f0f7-8ee3-4b2a-c015-542068f49fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".x.\n",
      "o.o\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OiRuj4_rP3SJ",
    "outputId": "2c1cca65-be7b-4f9b-afd3-771f32fbd2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 1, 0, 2, 1, 2]), 'valid', False)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8WGO5P7Pn0SK",
    "outputId": "7fca1411-ba85-4280-d509-0ab27f73e1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".x.\n",
      "oxo\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "3URlO_J8n3Ro",
    "outputId": "15f15d16-25c8-4704-e7d3-4f34c5b266bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 1, 2, 2, 1, 2]), 'valid', False)"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(hod_setki(policy, env.grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "T8jekJWNn85E",
    "outputId": "f4cbdb37-171e-4da5-e3cc-4ec0c31001d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..x\n",
      ".xo\n",
      "oxo\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhaoBlWUn_8s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RL_tic_tac_toe.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
